# 2021-08-14
무선통신 음성 코덱(G729a)에 맞춰 sox pipeline 구축
```
echo "$0: generating phone call noise"
sed -i '2~2 s\$\sox -t wav - -r 8k -t wav - | sox -t wav - -r 16k -t wav - | sox -t wav - -t wav - highpass 100 | sox -t wav - -t wav - lowpass 1000 | sox -t wav - -t wav - dither -s |\g' data/${trainset}/wav.scp
sed -i '2~8 s\$\sox -t wav - -t wav - gain 16 |\g' data/${trainset}/wav.scp
```

<br>

<br>

# 2021-08-15

sox 전처리 (band-pass 100-1000, dither, gain) 데이터 및 k-spon 말뭉치 데이터 merge 후 학습진행

라즈베리 파이와 스마트폰 간의 음성 입출력 문제 해결을 위한 토론진행

<br>

<br>

# 2021-08-16 14:50

학습 진행 과정에서 오류 발생 
```
local/chain/multi_condition/run_tdnn_1n.sh: exp/chain_rvb/tree_a/final.mdl already exists, refusing to overwrite it.
```

<br>

final.mdl 파일이 이미 존재하여 지우고 다시 학습 진행

```
data=./speechDATA
nCPU=28
. ./cmd.sh
. ./path.sh
sudo sudo local/chain/multi_condition/run_tdnn_1n.sh --nj $nCPU
```

<br>

<br>

# 2021-08-24

말뭉치 json파일 파싱 -> pypy3 json_parsing3.py

<br>

- 현재 corpus

모두의 말뭉치: 신문, 구어, 담화 말뭉치 parsing

ai hub: 소상공인 관련 parsing

ksponspeech: text 전처리

<br>

- 최종 사용 corpus

| text name          | lines         |
| :----------------- | :------------ |
| cafe.txt           | 8,000 lines   |
| cafemain.txt       | 160,000 lines |
| food.txt           | 5,000 lines   |
| kshopping.txt      | 180,000 lines |
| market.txt         | 3,600 lines   |
| restaurant.txt     | 15,800 lines  |
| restaurantmain.txt | 290,000 lines |
| store.txt          | 15,000 lines  |
| 합 계              | 677,400 lines |

<br>

시작시간: **2021-08-24 16:18**

예상 소요시간: 180.6시간 (7일 12시간)

소요시간: 1시간 20분



# 2021-08-28 21:03

## Trouble shooting

### \#1 Extend_vocab_demo.sh 실행을 위한 lexiconp 파일 생성

> 새로운 언어모델에 대한 lexiconp file의 부재 > prepare_lang.sh를 이용한 lexiconp 파일 생성 필요

- 새로운 언어모델을 만들기 위해 data/local/lm/run_task.sh를 사용하여 arpa file 및 lexicon file 생성 (lexiconp파일의 부재)
  - lexiconp 파일에 대한 설명은 Prepare_Data.md 참고
  - lexiconp file은 utils/prepare_lang.sh에서 생성
    - run_kspon.sh를 통하여 utils/prepare_lang.sh를 이용한 lexiconp 파일 생성하는 형식 확인 가능
    - extend_vocab_demo.sh의 Stage0에서 원본파일을 가지고 prepare_lang.sh 실행
- **[g2p](https://www.jask.or.kr/articles/xml/bQA1/)를 이용한 lexiconp 제작 중 (대략 18:00부터 진행)**



**★ utils/prepare_lang.sh 의 분석 필요: 왜 Stage0(원본 파일)에서는 사용하며, 새로운 Graph에 대해서는 g2p 학습을 진행하는 것인가**





### \#2 Silprob의 필요성에 대한 분석 필요

> 도대체 silence probability의 역할이 뭔지 분석 필요





# 2021-08-29 21:09

### \#1 decoding시 G.fst와 G.carpa의 사용 sequence 확인 필요





# 2021-08-30 20:53

### \#1 final.mdl은 뭐하는애?

> s5/local/chain/multi_condition/run_tdnn_1n.sh의 Stage 10을 보고... -찬현



### \#2 G.carpa로 해석하는 원리 파악 (진혁)

> 문득 rescoring을 하는게, 기존 HCLG로 하면서 동시에 Carpa로 하는건지
>
> 아니면 HCLG의 결과를 받아와서 Carpa에서 처리하는건지... (이렇게 된다면, 기존 HCLG가 쓰레기면 rescoring을 암만 해봤자 쓰레기값이 나오겠찌..?)

- 한비: 그럼 애초에 HCLG만들때 tglarge를 사용하는게 어떨까? (속도비교 필요)

