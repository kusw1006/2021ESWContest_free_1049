scriptdir=./data/local/lm/buildLM/_scripts\_

srcdir=./data/local/lm/buildLM/_corpus\_



# ./data/local/lm/run.sh

## $scriptdir/buildlexicon.sh	$srcdir	$SegModelTxt

> 오약: Morphemes 모아서 FinalList(단어) 만들고 Lexicon 제작

### $scriptdir/genPronunciation.py

> $srcdir/finalList

### $scriptdir/genPhoneSeq.py

> $srcdir/finalList

### $scriptdir/genLexicon.py

> $srcdir/Lexicon



## $scriptdir/buildNGRAM.sh	$srcdir

> 요약: arpa파일 제작

### ngram-count -order $ngram -unk -map-unk "<UNK\>" -vocab $vocab -text $txt.train -lm $txt.lm.tg.arpa.gz -kndiscount -interpolate

> ngram count

### ngram -order 3 -lm $txt.lm.tg.arpa.gz -ppl $txt.test

> arpa파일 제작

### ngram -prune $prune_thresh_small -lm $txt.lm.tg.arpa.gz -write-lm $txt.lm.tgsmall.arpa.gz

> pruned된 arpa파일 제작











# s5/run_openslr.sh

## ./local/format_lms.sh --src-dir data/lang data/local/lm

### arpa2fst --disambig-symbol=#0 --read-symbol-table=$test/words.txt - $test/G.fst

> arpa파일을 이용해서 G.fst 제작



## utils/build_const_arpa_lm.sh data/local/lm/zeroth.lm.tg.arpa.gz data/lang data/lang_test_tglarge

> <arpa-lm-path> <old-lang-dir> <new-lang-dir>

### arpa-to-const-arpa --bos-symbol=$bos --eos-symbol=$eos --unk-symbol=$unk "gunzip -c $arpa_lm | utils/map_arpa_lm.pl $new_lang/words.txt|" $new_lang/G.carpa

> const arpa 제작



## utils/mkgraph.sh data/lang_test_tgsmall exp/tri4b exp/tri4b/graph_tgsmall

> HCLG 그래프 제작













# ./local/chain/multi_condition/run_tdnn_1n.sh

## local/nnet3/multi_condition/run_ivector_common.sh --stage $stage --speed-perturb ${speed_perturb} --num-data-reps ${num_data_reps} --rvb-affix ${nnet3_affix}

> 속도 변형 및 reverberate_data_dir 을 이용한 노이즈 추가 뒤, mfcc 제작 및 cmvn 추정
>
> 또한 화자인식을 위한 ivector 학습 진행

### steps/data/reverberate_data_dir.py [options...] <in-data-dir\> <out-data-dir\>

> 노이즈 및 잔향 추가



## steps/nnet3/chain/gen_topo.py $nonsilphonelist $silphonelist >$lang/topo

>  topology 관련



## steps/align_fmllr_lats.sh --nj $nj --cmd "$train_cmd" ${lores_train_data_dir} data/lang $gmm_dir $clean_lat_dir

> Get the alignments as lattices (gives the chain training more freedom). use the same num-jobs as the alignments
>
> + create the lattices for the reverberated data
> + 이건 alignments of alternative pronumciations들의 lattices (lat.*.gz) 제작

### gmm-align-compiled --transition-scale=0.0 --self-loop-scale=0.0 --acoustic-scale=$acoustic_scale     --beam=$beam --retry-beam=$retry_beam "$alimdl_cmd"   "ark:gunzip -c $dir/fsts.JOB.gz|" "$sifeats" "ark:|gzip -c >$dir/pre_ali.JOB.gz"

> ```
> gmm-latgen-faster는 그래프 자체에 transition-probs 추가를 지원하지 않기 때문에 컴파일된 그래프로 구워야 합니다. 이것은 다른 스크립트가 전환 프로브 없이 그래프를 작성하기 때문에 이전에 컴파일된 그래프를 재사용할 수 없다는 것을 의미합니다.
> ```

### gmm-latgen-faster --max-active=$max_active --acoustic-scale=$acoustic_scale --beam=$final_beam    --lattice-beam=$final_beam --allow-partial=false --word-determinize=false   "$mdl_cmd" "ark:gunzip -c $dir/fsts.JOB.gz|" "$feats"   "ark:|gzip -c >$dir/lat.JOB.gz"

> alternate pronunciationfmf vhgkagks lattice 생성 

### lattice-best-path --acoustic-scale=$acoustic_scale "ark:gunzip -c $dir/lat.JOB.gz |"   ark:/dev/null "ark:|gzip -c >$dir/ali.JOB.gz" 

> If generate_alignments is true, ali.*.gz is generated in lats dir





## lattice-copy "ark:gunzip -c $clean_lat_dir/lat.*.gz |" ark,scp:$lat_dir/temp/lats.ark,$lat_dir/temp/lats.scp

> We use the lattices/alignments from the clean data for the reverberated data.



## steps/nnet3/chain/train.py --stage $train_stage \

  --cmd "$decode_cmd" \

  --feat.online-ivector-dir=$train_ivector_dir \

  --feat.cmvn-opts "--norm-means=false --norm-vars=false" \

  --chain.xent-regularize $xent_regularize \

  --chain.leaky-hmm-coefficient 0.1 \

  --chain.l2-regularize 0.0 \

  --chain.apply-deriv-weights false \

  --chain.lm-opts="--num-extra-lm-states=2000" \

  --trainer.max-param-change $max_param_change \

  --trainer.num-epochs $num_epochs \

  --trainer.frames-per-iter 1500000 \

  --trainer.optimization.num-jobs-initial $num_jobs_initial \

  --trainer.optimization.num-jobs-final $num_jobs_final \

  --trainer.optimization.initial-effective-lrate $initial_effective_lrate \

  --trainer.optimization.final-effective-lrate $final_effective_lrate \

  --trainer.num-chunk-per-minibatch $minibatch_size \

  --egs.stage $get_egs_stage \

  --egs.chunk-width $chunk_width \

  --egs.dir "$common_egs_dir" \

  --egs.opts "--frames-overlap-per-eg 0" \

  --cleanup.remove-egs $remove_egs \

  --use-gpu true \

  --feat-dir $train_data_dir \

  --tree-dir $tree_dir \

  --lat-dir $lat_dir \

  --dir $dir

> 학습… 시키는 python 파일



##  utils/lang/check_phones_compatible.sh  data/lang_test_tgmed/phones.txt $lang/phones.txt



## utils/mkgraph.sh   --self-loop-scale 1.0 data/lang_test_tgmed   $tree_dir $tree_dir/graph_tgmed

> HCLG.fst 그래프 제작

